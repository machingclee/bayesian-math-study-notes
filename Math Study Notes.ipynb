{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06a900e6-a610-47cd-9e1f-03a9aaf7dcf5",
   "metadata": {},
   "source": [
    "In discrete case, a **distribution** is a **list of outcomes** of an experiment and the probability associated with each outcome.\n",
    "\n",
    "Namely, \n",
    "$$\\text{Distribution}=\\big\\{(\\text{outcome}_i,p_i ):i\\in A\\big\\}$$\n",
    "for some countable set $A$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a63bca-148b-4b55-93d0-5f60edd5f046",
   "metadata": {},
   "source": [
    "$\\newcommand{\\var}{\\mathrm{Var}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40262ac9-2b5f-4141-8f5a-9f05de58fb10",
   "metadata": {},
   "source": [
    "We usually denote such outcome as the value of a random varaible $X$.  For discrete random variable (an outcome, $X$, with unknown probability measure space), the probabilities $p_i$'s have one-one correspondance with frequencies $f_i$'s."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7040d099-a382-4c91-9a3b-3345d66d255b",
   "metadata": {},
   "source": [
    "### Multinormal Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561c0c9b-79c7-44f8-8f68-a0925a215570",
   "metadata": {},
   "source": [
    "Suppose $X:\\Omega\\to\\mathbb R^d$ is a  random variable defined on $(\\Omega,\\mathcal F,\\mathbb P)$, the measure $\\mu_X:A\\mapsto \\mathbb P(X^{-1}(A))$ defines a measure on $\\mathbb R^d$, called the **distribution of $X$**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c15724d-f890-4b36-8076-bcefa7ff8a52",
   "metadata": {},
   "source": [
    "**Definition.** A random variable $X:(\\Omega, \\mathcal F, \\mathbb P)\\to \\mathbb R^d$ is said to be **discrete** if there is a countable set $C$ such that \n",
    "$$\n",
    "\\mathbb P(X\\in C)=1.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb347d6a-c46a-4b24-83e9-189f1b7ea3c0",
   "metadata": {},
   "source": [
    "**Definition.** A randome variable $X:(\\Omega, \\mathcal F, \\mathbb P)\\to \\mathbb R^d$ is said to be **continous** if $\\mu_X$ is **absolutely continuous** w.r.t. the Lebesgue measure $\\mathcal L^d$ on $\\mathbb R^d$, in that case, there is a unique integrable function $f_X$ such that \n",
    "$$\n",
    "\\mathbb P(X\\in A) = \\int_A f_X(x)\\,d\\mathcal L^d(x)\\qquad \\text{for every measurable $A$}.\n",
    "$$\n",
    "$f_X$ is called the **probability density function** of $X$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2407a3f-8d01-4c7d-8265-5203f697a0dd",
   "metadata": {},
   "source": [
    "For example, when $d=1$, if we assume a data set of points on $\\mathbb R$ follow a normal distribution, then the point where data accumulate most obviously should be the center, the mean, of our distribution.\n",
    "\n",
    "When $d=2$, we  use such an $X$  to fit data in $\\mathbb R^2$ whose \"distribution/separation/density\" spreads like a normal distribution in a radial fashion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd89b0b-d4cc-4069-b313-0087761d13e8",
   "metadata": {},
   "source": [
    "<center>\n",
    "  <img width=\"350\" src=\"./images/image_02.png\">\n",
    "</center>\n",
    "Here the value $f(x_1,x_2)$ in $z$-axis denotes the \"fraction of data\" appear if we draw a small circle around $(x_1,x_2)$. If $f(x_1,x_2)$ is the peak, that means the data points cluster most rapidly near $(x_1,x_2)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79d53cb-58d1-4a04-a2dc-32f35d055d74",
   "metadata": {},
   "source": [
    "It also makes sense to say that a list of integers follow a normal distribution if the integer-frequency table plots like a normal distribution. Just think of a set of points in $\\mathbb R$ now collapse into a bin of length $1$ by taking floor function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525951c3-fcf3-48a0-8736-8e1c40442fef",
   "metadata": {},
   "source": [
    "**Definition.** For $d$-dimensional case, the pdf of a **multinormal distribution** $X$ evaluted at $x\\in \\mathbb R^d$ is defined by \n",
    "$$\n",
    "\\mathcal N(x;\\mu, \\Sigma) = \\frac{1}{(2\\pi)^{d/2}\\sqrt{\\det \\Sigma}} \\exp \\left(-\\frac{1}{2}(x-\\mu)^T\\Sigma^{-1}(x-\\mu)\\right).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3eb32bb-8ec8-4517-a0e5-9997e8afa271",
   "metadata": {},
   "source": [
    "Where $\\Sigma$ is a positive definite variance-covariance matix of the Gaussian, with $\\Sigma_{ij}=\\mathrm{Conv}(X_i,X_j)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251594b8-2ea1-46f1-b8c4-b29dd485bf76",
   "metadata": {},
   "source": [
    "**Example.** Suppose that $X_i \\sim \\mathcal N(\\mu_i,\\sigma_i)$ for $i=1,2$, then define $X=[X_1, X_2]$. Now their pdf are respectively\n",
    "$$\n",
    "f_{X_1}(x_1) = \\frac{1}{Z_1} \\exp \\left\\{-\\frac{1}{2\\sigma_1^2}(x_1-\\mu_1)^2 \\right\\} \\quad \\text{and}\\quad f_{X_2}(x_2) = \\frac{1}{Z_2} \\exp \\left\\{-\\frac{1}{2\\sigma_1^2}(x_2-\\mu_2)^2 \\right\\},\n",
    "$$\n",
    "where $Z_i = \\sigma_i\\sqrt{2\\pi}$. The pdf of $X$ is the joint pdf of $X_1$ and $X_2$,  given by \n",
    "$$\n",
    "f_X(x)=f_X(x_1,x_2) = f_{X_1}(x_1)f_{X_2}(x_2) = \\frac{1}{Z_1Z_2} \\exp \\left\\{-\\frac{1}{2}(x-\\mu)^T \\Sigma^{-1} (x-\\mu) \\right\\}\n",
    "$$\n",
    "where $x=[x_1,x_2],\\mu=[\\mu_1,\\mu_2]$ and $\\Sigma = \\mathrm{diag}(\\sigma_1^2, \\sigma_2^2)$. Interpret the vector as column when necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb01a93a-07eb-4614-81f7-2fab52c478d1",
   "metadata": {},
   "source": [
    "### Conditional Expectation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dadb008-1405-412d-bda5-7872249531ba",
   "metadata": {},
   "source": [
    "Assume that $X$ and $Y$ are discrete random variable, we will have all the same result for continuous ones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c71acc-d705-4d08-a75d-74bc93854bf2",
   "metadata": {},
   "source": [
    "* $$P(X=x|Y=y) = \\frac{P(X=x\\,\\text{ and }\\,Y=y)}{P(Y=y)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6143c154-47aa-48d0-a022-44fc20a65b1e",
   "metadata": {},
   "source": [
    "* $$f_{X|Y} (x|y) = P(X=x| Y=y)$$\n",
    "  Here for the moment $X|Y$ is simply a notation that carries no specific meaning. Later we will treat it as a parametrized family of random variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90c3ce3-fc76-4ebd-ad1b-b4a56b08d645",
   "metadata": {},
   "source": [
    "* $$\\mu_{X|Y=y} = E(X|Y=y) = \\sum_x xf_{X|Y}(x|y)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092330aa-4b94-4ce4-b204-0a89e5f8cb73",
   "metadata": {},
   "source": [
    "* $E(X|Y=y)$ is a number depending on $y$, and indeed if we let $y$ varies, we get a new random variable:\n",
    "$$E(X|Y) : y\\mapsto E(X|Y=y)$$\n",
    "\n",
    "    Suppose \n",
    "    $$\n",
    "    Y = \\begin{cases} \n",
    "    1 & \\text{widht probability $1/8$}\\\\\n",
    "    2 & \\text{widht probability $7/8$}.\n",
    "    \\end{cases}\n",
    "    $$\n",
    "    We can define a $y$-parametrized random variable by \n",
    "    $$ \n",
    "    X|Y =  \\begin{cases} \n",
    "    2Y & \\text{widht probability $3/4$}\\\\\n",
    "    3Y & \\text{widht probability $1/4$}\n",
    "    \\end{cases}\n",
    "    $$\n",
    "\n",
    "  * If $Y=1$, \n",
    "    $$X|(Y=1) = \\begin{cases} \n",
    "    2 & \\text{widht probability $3/4$}\\\\\n",
    "    3 & \\text{widht probability $1/4$}\n",
    "    \\end{cases}\\quad \n",
    "    $$ and hence $$E(X|Y=1) = 2\\times \\frac{3}{4} + 3\\times \\frac{1}{4} = \\frac{9}{4}.$$\n",
    "    \n",
    "   * If $Y=2$, \n",
    "     $$X|(Y=2) = \\begin{cases} \n",
    "     4 & \\text{widht probability $3/4$}\\\\\n",
    "     6 & \\text{widht probability $1/4$}\n",
    "     \\end{cases}\n",
    "     $$ and hence $$E(X|Y=2) = 4\\times \\frac{3}{4} + 6\\times \\frac{1}{4} = \\frac{18}{4}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c043df2a-6f1f-4618-910f-9b027b1000eb",
   "metadata": {},
   "source": [
    "* $X|Y$ is nothing but a **family of random variables** and $h(Y):=E(X|Y)$ is a new random variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce52e370-9743-4d52-b0c1-82926e40d22b",
   "metadata": {},
   "source": [
    "* Similarly, $\\mathrm{Var}(X|Y)$ is also a random variable and \n",
    "$$\n",
    "h(Y):=\\boxed{\\mathrm{Var}(X|Y) = E(X^2|Y) - (E(X|Y))^2 = E[(X-\\mu_{X|Y})^2|Y]}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95afe75-9368-4e5b-9204-fc7b930c38a1",
   "metadata": {},
   "source": [
    "* $E(g(X)) = E_Y(E(g(X)|Y))$ because \n",
    "    $$\n",
    "    E_Y(E(g(X)|Y)) \n",
    "    = E_Y\\left[\\sum_x g(x)P(X=x | Y)\\right]\n",
    "    = \\sum_y\\left[\\sum_x g(x)P(X=x | Y=y)\\right]P(Y=y)\n",
    "    $$\n",
    "\n",
    "    The RHS above becomes $\\sum_x g(x)P(X=x) = E(g(X))$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd003b37-fee8-487d-9b44-d352d0e9da48",
   "metadata": {},
   "source": [
    "**Example.** Fraser runs a dolphin-watch business. Every day, he is unable to run the trip due to bad weather with probability $p$, independently of all other days. Fraser works every day except the bad-weather\n",
    "days, which he takes as holiday\n",
    "\n",
    "\n",
    "Let $Y$ be the number of consecutive days Fraser has to work between badweather days. Let $X$ be the total number of customers who go on Fraser's trip in this period of $Y$ days. Conditional on $Y$, the distribution of $X$ is\n",
    "$$(X | Y ) \\sim \\mathrm{Poisson}(\\mu Y).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af695373-4f08-4325-bbb0-de7c0a879a08",
   "metadata": {},
   "source": [
    "* $Y\\sim \\mathrm{Geometric}(p)$, because \"bad weather\" can be treated as a \"success\" trial that the \"experiment\" must be stopped. In this case, $E(Y) =(1-p)/p$ and $\\mathrm{Var}(Y)= (1-p)/p^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66fc3b9-e918-4e6e-8e54-3580305094ca",
   "metadata": {},
   "source": [
    "* It is given that $(X | Y ) \\sim \\mathrm{Poisson}(\\mu Y)$, therefore \n",
    "$$\n",
    "E(X|Y) = \\mathrm{Var}(X|Y) = \\mu Y.\n",
    "$$\n",
    "By the Law of Total Expectation, \n",
    "$$\n",
    "E(X) = E_Y(E(X|Y)) = E_Y(\\mu Y) = \\mu E_Y(Y) = \\frac{\\mu(1-p)}{p}.\n",
    "$$\n",
    "By the law of Tatal Variance,\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathrm{Var}(X) &= E_Y[\\mathrm{Var}(X|Y)] + \\mathrm{Var}_Y(E(X|Y))\\\\\n",
    "&= E_Y(\\mu Y) + \\mathrm{Var}_Y(\\mu Y)\\\\\n",
    "&=\\mu\\frac{1-p}{p} +\\mu^2\\frac{1-p}{p^2} \\\\\n",
    "&= \\frac{\\mu(1-p)(1+p)}{p^2}\\\\\n",
    "&= E_Y(\\mu Y) + \\mathrm{Var}_Y(\\mu Y) \\\\\n",
    "&=\\mu\\frac{1-p}{p} +\\mu^2\\frac{1-p}{p^2} \\\\\n",
    "&= \\frac{\\mu(1-p)(1+p)}{p^2}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfa79c3-f762-4133-b96f-b04a5924224b",
   "metadata": {},
   "source": [
    "### Introduction to Bayesian Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc0e447-3cc9-4899-b943-ca93a585706e",
   "metadata": {},
   "source": [
    "#### Bayesian way of Thinking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16e842d-55df-48d9-874d-d36946a357bf",
   "metadata": {},
   "source": [
    "Let $\\theta$ be a set of parameters that affect the outcome $x$. We call the assumption $P(\\theta) = \\alpha$ a **prior probability** and call, for a new outcome $x'$, \n",
    "$$\n",
    "P(\\theta|x') = \\frac{P(x'|\\theta)P(\\theta)}{\\sum_{i} P(x'|\\theta_i)P(\\theta_i)}\n",
    "$$\n",
    "a **posterior probability**. We also say that we **update** the prior by making use of the posterior probability as our new prior probability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4de772f-5cea-4152-b6f9-a4560e72a092",
   "metadata": {},
   "source": [
    "#### Formulas on distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919d69cf-7db5-4e63-8ffa-c425932177ca",
   "metadata": {},
   "source": [
    "* $p(a|b) = \\displaystyle\\int p(a,c|b)\\,dc$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30cce41-aa61-4558-9780-c1dbfde180aa",
   "metadata": {},
   "source": [
    "* $p(a|b) = \\displaystyle\\int p(a|b,c)p(c)\\,dc$ when $b$ and $c$ are independent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b112b04-f123-40e2-9489-eae6b56037aa",
   "metadata": {},
   "source": [
    "* $\\displaystyle p(a|b,c) = \\frac{p(b|a,c)p(a|c)}{\\displaystyle \\int p(b|a',c)p(a'|c)\\,da'}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d89596-80b1-4e77-9672-8df0e7524089",
   "metadata": {},
   "source": [
    "* $p(a,b|c) = p(a|b,c)p(b|c)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f1fada-98c6-4a75-b4e4-cf21acc4af98",
   "metadata": {},
   "source": [
    "* $\\displaystyle p(a|b) = \\frac{p(a,c|b)}{p(c|a,b)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fbed9e-c6b3-41f2-bda6-d45416659c88",
   "metadata": {},
   "source": [
    "* $p(a|b)p(b) + p(a|\\bar{b})p(\\bar{b}) = p(a)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07600050-1f48-42e5-9b30-6a21202fdd57",
   "metadata": {},
   "source": [
    "* If $p(a,b,c) = p(a|b)p(b|c)p(c)$, we cannot conclude $a$ and $c$ are independent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537ee03d-a6f2-4f78-a17c-a6e150e3128f",
   "metadata": {},
   "source": [
    "* If $p(a,b,c,d) = p(a|b)p(b)p(c|d)p(d)$, we can conclude $a$ and $c$ are independent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8d8a44-68cb-413a-b822-6b05f9936069",
   "metadata": {},
   "source": [
    "* You have a kettle that boils water. You pour water up to level $L_0$ and turn the kettle on.  Over time, temperature $T$ starts to increase. At time $t$, level of water is $L$. Since water is boiling, water level slightly oscillates and so can be considered random. You also know that the height of a kettle is limited. If at some point water level exceeds this value, water will split on a table. We will denote this event as a binary random variable $O$ (overflow). Our goal is to determine the maximum allowed initial water level $L_{max}$  so that we can write it down in a kettle manual. Normally we would like to find $L_{max}$ for which, for example, $P(O|L_0 = L_{max}) = 0.001$: if you pour this amount of water, overflow will occur with a fairly low probability.\n",
    "\n",
    "  We will construct a Bayesian network and select probability distributions needed for the model.\n",
    "\n",
    "  Our Bayesian network is as follows.\n",
    "\n",
    "  The graphical model\n",
    "\n",
    "  <center>\n",
    "    <img width=\"200\" src=\"images/graphical_model.png\"/>\n",
    "   </center>\n",
    "\n",
    "    can be described by the joint distribution function:\n",
    "\n",
    "  $$p(O,L,L_0,T,t)=p(O|L)p(L|L_0,T)p(T|L_0,t)P(L_0)P(t)$$\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6aad67d-0ba5-4bb0-80a0-1e5e5a403c8c",
   "metadata": {},
   "source": [
    "### Latent Variable Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8d3d23-99ac-4352-bbe8-4f32534eb69c",
   "metadata": {},
   "source": [
    "* To calculate ***posterior probability*** $P(\\theta | x)$ we need to know how to compute $P(x|\\theta)$ by Bayse formula. To simplify the problem we may try to assume there are hidden random variable $z_i$ that affects $x_i$, namely, $\\boxed{z_i}\\to \\boxed{x_i}$. Therefore it makes sense to discuss \n",
    "$$\n",
    "\\begin{aligned}\n",
    "p(x_i|\\theta) \n",
    "&= \\sum_c p(x_i, c|\\theta) \\\\ \n",
    "&= \\sum_c p(x_i|z_i=c,\\theta) p(z_i=c|\\theta).\n",
    "\\end{aligned}\n",
    "$$\n",
    "Where $c$ can be think of as \"class\", \"label\", etc, in integer. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9f7a57-7148-4f27-ada4-2af40b9804c9",
   "metadata": {},
   "source": [
    "* It then makes sense to consider the maximum likelihood problem by maximizing\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\ln p(x|\\theta)&=\\ln \\prod_i p(x_i|\\theta)\\\\\n",
    "&=\\sum_i \\ln p(x_i|\\theta)\\\\\n",
    "&=\\sum_i \\ln\\left[ \\sum_c p(x_i,z_i= c|\\theta)\\right]\\\\\n",
    "&=\\sum_i \\ln\\left[ \\sum_c \\frac{q(z_i=c)}{q(z_i=c)} p(x_i,z_i= c|\\theta)\\right]\\\\\n",
    "&\\ge \\underbrace{\\sum_i \\sum_cq(z_i=c)\\ln \\left(\\frac{ p(x_i,z_i= c|\\theta)}{q(z_i=c)}\\right)}_{:=\\mathcal L(\\theta, q)},\n",
    "\\end{aligned}\n",
    "$$\n",
    "where $q$ is any distribution of $z$ and the last line follows from Jensen's inequality. We try to maximize the lower bound $\\mathcal L$ w.r.t $q$ and then $\\theta$. Optimially for each optimization step, we can find $q_\\theta$ such that $\\mathcal L(\\theta,q_\\theta)$ touches our target, and move $\\theta$ to attains a better maxima of $\\mathcal L$ that eventually is also a maxima of our log-likelihood."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f04ff3-1b77-4416-a243-7fb24f05772a",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <img width=\"300\" src=\"images/likelihood.png\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c3973b-0db6-4506-93a2-8a9a0a48b192",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-2.4-cuda11",
   "language": "python",
   "name": "tensorflow-2.4-cuda11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": true,
  "toc-showcode": true,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
